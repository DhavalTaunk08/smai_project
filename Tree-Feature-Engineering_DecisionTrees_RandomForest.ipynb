{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20420,
     "status": "ok",
     "timestamp": 1638700696630,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "mZMuXFRphg5t",
    "outputId": "05e240e4-f487-4f76-d09d-db420b2947c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1638700696631,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "IT5Jk4ptyHma",
    "outputId": "fd091ec0-adf4-4fd6-9900-f5020bb9b1a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/.shortcut-targets-by-id/1AtQJMrriX3WOs5N0Pda_qEvUQ7x_w36i/SMAI_Project_2021\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/MyDrive/SMAI_Project_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all Essential Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1814,
     "status": "ok",
     "timestamp": 1638700698435,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "_eC733kryLNM"
   },
   "outputs": [],
   "source": [
    "# All external libraries used throughout the notbook are listed here\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier as logreg_w_sgd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1638700699592,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "nyREFPthyTnO"
   },
   "outputs": [],
   "source": [
    "ROOT = \"/content/gdrive/MyDrive/SMAI_Project_2021/\"\n",
    "\n",
    "SAVED_MODEL_PATH = ROOT + \"models/\"\n",
    "\n",
    "N_GRAM_FEAT_PATH = ROOT + \"ngram_features/\"\n",
    "TREE_FEAT_PATH = ROOT + \"tree_features/\"\n",
    "\n",
    "UNIGRAM_PATH = N_GRAM_FEAT_PATH + \"unigrams/\"\n",
    "BIGRAM_PATH = N_GRAM_FEAT_PATH + \"bigrams/\"\n",
    "TRIGRAM_PATH = N_GRAM_FEAT_PATH + \"trigrams/\"\n",
    "UNIGRAM_SCRAP = N_GRAM_FEAT_PATH + \"scrap/unigrams/\"\n",
    "BIGRAM_SCRAP = N_GRAM_FEAT_PATH + \"scrap/bigrams/\"\n",
    "TRIGRAM_SCRAP = N_GRAM_FEAT_PATH + \"scrap/trigrams/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJUT_oLhrRPv"
   },
   "outputs": [],
   "source": [
    "!mkdir tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMI8cNlWfMxi",
    "outputId": "40f7b90a-90bd-4cba-b823-da825fa654f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sentences = train['question1'].tolist() + train['question2'].tolist()\n",
    "max_len_sent = len(max(total_sentences, key=lambda x : len(word_tokenize(str(x)))).split())\n",
    "\n",
    "max_len_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGQjBT07fMuc"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "class CreateTreeFeatures():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_length_feature(self, question1, question2, vector):\n",
    "        l1 = len(question1.split())\n",
    "        l2 = len(question2.split())\n",
    "        vector.append(l1)\n",
    "        vector.append(l2)\n",
    "        vector.append(l1-l2)\n",
    "        vector.append(l1/l2)\n",
    "\n",
    "        return vector\n",
    "\n",
    "    def get_count_lowercased(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1) if word.islower()]\n",
    "        q2 = [word for word in word_tokenize(question2) if word.islower()]\n",
    "\n",
    "        count = len(set(q1) & set(q2))\n",
    "        \n",
    "        vector.append(count)\n",
    "        vector.append(count/237)\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def get_count_lowercased_without_stopwords(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1) if word.islower() and word not in stop_words]\n",
    "        q2 = [word for word in word_tokenize(question2) if word.islower() and word not in stop_words]\n",
    "\n",
    "        count = len(set(q1) & set(q2))\n",
    "        \n",
    "        vector.append(count)\n",
    "        vector.append(count/237)\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def same_last_words(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1)]\n",
    "        q2 = [word for word in word_tokenize(question2)]\n",
    "\n",
    "        vector.append(q1[-1]==q2[-1])\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def get_count_uppercased(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1) if word.isupper()]\n",
    "        q2 = [word for word in word_tokenize(question2) if word.isupper()]\n",
    "\n",
    "        count = len(set(q1) & set(q2))\n",
    "        \n",
    "        vector.append(count)\n",
    "        vector.append(count/237)\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def same_prefix(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1)]\n",
    "        q2 = [word for word in word_tokenize(question2)]\n",
    "\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(3)]))\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(3)])/237)\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(4)]))\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(4)])/237)\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(5)]))\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(5)])/237)\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(6)]))\n",
    "        vector.append(sum([q1[:i]==q2[:i] for i in range(6)])/237)\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def misc_features(self, question1, question2, vector):\n",
    "        q1 = [word for word in word_tokenize(question1)]\n",
    "        q2 = [word for word in word_tokenize(question2)]\n",
    "\n",
    "        vector.append('not' in q1)\n",
    "        vector.append('not' in q2)\n",
    "        vector.append('not' in q1 and 'not' in q2)\n",
    "\n",
    "        q11 = [word for word in q1 if word.isdigit()]\n",
    "        q21 = [word for word in word_tokenize(question2) if word.isdigit()]\n",
    "        vector.append(len(set(q11) and set(q21)))\n",
    "\n",
    "        q12 = [ps.stem(word) for word in q1]\n",
    "        q22 = [ps.stem(word) for word in q2]\n",
    "\n",
    "        vector.append(len(set(q12) & set(q22)))\n",
    "        vector.append(len(set(q12) & set(q22))/237)\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    def create_feature_vector(self, question1, question2):\n",
    "        vector = []        \n",
    "        vector = self.get_length_feature(question1, question2, vector)\n",
    "        vector = self.get_count_lowercased(question1, question2, vector)\n",
    "        vector = self.get_count_lowercased_without_stopwords(question1, question2, vector)\n",
    "        vector = self.same_last_words(question1, question2, vector)\n",
    "        vector = self.get_count_uppercased(question1, question2, vector)\n",
    "        vector = self.same_prefix(question1, question2, vector)\n",
    "        vector = self.misc_features(question1, question2, vector)\n",
    "\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTenT7vsqeNT"
   },
   "outputs": [],
   "source": [
    "create_tree_feature = CreateTreeFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-LPN2wN0GOM",
    "outputId": "b73e061f-e51c-4b6b-d182-6756e971eb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\tquora_question_pairs.zip  test_data.csv   tree_features\n",
      "models\t\tsmai.ipynb\t\t  train.csv\t  val_data.csv\n",
      "ngram_features\ttest.csv\t\t  train_data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLyvrfYhqeFb"
   },
   "outputs": [],
   "source": [
    "feature_vector = []\n",
    "for i, row in tqdm(train_data.iterrows()):\n",
    "    feature_vector.append(create_tree_feature.create_feature_vector(str(row['question1_preprocessed']), str(row['question2_preprocessed'])))\n",
    "\n",
    "with open('tree_features/train.pickle', 'wb') as f:\n",
    "    pickle.dump(feature_vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zG-b63P-fMrx",
    "outputId": "950f6399-a96d-4e4c-8986-28ab981355bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80858it [03:29, 386.61it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "for i, row in tqdm(val_data.iterrows()):\n",
    "    feature_vector.append(create_tree_feature.create_feature_vector(str(row['question1_preprocessed']), str(row['question2_preprocessed'])))\n",
    "\n",
    "with open('tree_features/val.pickle', 'wb') as f:\n",
    "    pickle.dump(feature_vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntRHXbzVZEL-",
    "outputId": "7b47270f-a52e-46d2-aa28-78000c9c89fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40429it [01:44, 387.83it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "for i, row in tqdm(test_data.iterrows()):\n",
    "    feature_vector.append(create_tree_feature.create_feature_vector(str(row['question1_preprocessed']), str(row['question2_preprocessed'])))\n",
    "\n",
    "with open('tree_features/test.pickle', 'wb') as f:\n",
    "    pickle.dump(feature_vector, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5283,
     "status": "ok",
     "timestamp": 1638700708044,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "W1GD9xEVyWso"
   },
   "outputs": [],
   "source": [
    "# train_data.to_csv('train_data.csv', index=False)\n",
    "# val_data.to_csv('val_data.csv', index=False)\n",
    "# test_data.to_csv('test_data.csv', index=False)\n",
    "#with open(TREE_FEAT_PATH + \"train.pickle\", \"rb\") as f_train:\n",
    "\n",
    "train_data = pd.DataFrame(pd.read_pickle(TREE_FEAT_PATH + \"train.pickle\"))\n",
    "val_data = pd.DataFrame(pd.read_pickle(TREE_FEAT_PATH + \"val.pickle\"))\n",
    "test_data = pd.DataFrame(pd.read_pickle(TREE_FEAT_PATH + \"test.pickle\"))\n",
    "\n",
    "# Combine both Training and Validation data.\n",
    "train_val_data = pd.concat([train_data, val_data], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5849,
     "status": "ok",
     "timestamp": 1638700713859,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "KaZC9IgsbxaI"
   },
   "outputs": [],
   "source": [
    "# Import labels...\n",
    "train_labels = pd.read_csv(ROOT + \"train_data.csv\", index_col=0).is_duplicate.values\n",
    "val_labels = pd.read_csv(ROOT + \"val_data.csv\", index_col=0).is_duplicate.values\n",
    "test_labels = pd.read_csv(ROOT + \"test_data.csv\", index_col=0).is_duplicate.values\n",
    "\n",
    "# Combine train and val labels.\n",
    "train_val_labels = np.concatenate((train_labels, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i0SWC30jfpW"
   },
   "source": [
    "# Replicate Paper Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20LB3JBx6WVW"
   },
   "source": [
    "## Decision Tree training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2664,
     "status": "ok",
     "timestamp": 1638700826711,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "s2xX3z8rMk7Q"
   },
   "outputs": [],
   "source": [
    "# Create an instance of decision Tree..\n",
    "dt = DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)\n",
    "# Train the DT.\n",
    "dt = dt.fit(train_val_data, train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1638700829729,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "cL15DGnkg2iF",
    "outputId": "0047d41e-f1aa-4cf3-d144-a63655f13c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score for Decision Tree = 0.720\n",
      "F1-Score for Decision Tree = 0.634\n"
     ]
    }
   ],
   "source": [
    "# Predict on vals.\n",
    "pred = dt.predict(test_data)\n",
    "# Accuracy and F1 score.\n",
    "f1_dt = f1_score(test_labels, pred)\n",
    "acc_dt = accuracy_score(test_labels, pred)\n",
    "# Print the scores.\n",
    "print(\"Accuracy-Score for Decision Tree = %.3f\"%acc_dt)\n",
    "print(\"F1-Score for Decision Tree = %.3f\"%f1_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYnJydzhhtv5"
   },
   "source": [
    "## Random Forest Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma9brydfhtv6"
   },
   "outputs": [],
   "source": [
    "# Create an instance of decision Tree..\n",
    "rf = RandomForestClassifier(max_depth=None, n_estimators = 50, min_samples_leaf=5, n_jobs = -1)\n",
    "# Train the DT.\n",
    "rf = rf.fit(train_val_data, train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1637835488957,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "arP7UpXHhtv7",
    "outputId": "f0f1263f-e6b4-41c8-82a6-3e681674d09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score for Random Forest Classifier = 0.735\n",
      "F1-Score for Random Forest Classifier = 0.646\n"
     ]
    }
   ],
   "source": [
    "# Predict on vals.\n",
    "pred_rf = rf.predict(test_data)\n",
    "# Accuracy and F1 score.\n",
    "f1_rf = f1_score(test_labels, pred_rf)\n",
    "acc_rf = accuracy_score(test_labels, pred_rf)\n",
    "# Print the scores.\n",
    "print(\"Accuracy-Score for Random Forest Classifier = %.3f\"%acc_rf)\n",
    "print(\"F1-Score for Random Forest Classifier = %.3f\"%f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "533yR3ZujzxZ"
   },
   "source": [
    "## Gradient Boosting Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cfo8xxQljzxb"
   },
   "outputs": [],
   "source": [
    "# Create an instance of decision Tree..\n",
    "gb = GradientBoostingClassifier(max_depth=4, n_estimators = 500)\n",
    "# Train the DT.\n",
    "gb = gb.fit(train_val_data, train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1637835487075,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "Dqp9baSwjzxd",
    "outputId": "7accb24a-8fe9-4dca-8eec-cc530b4d94bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score for Decision Tree = 0.733\n",
      "F1-Score for Decision Tree = 0.646\n"
     ]
    }
   ],
   "source": [
    "# Predict on vals.\n",
    "pred_gb = gb.predict(test_data)\n",
    "# Accuracy and F1 score.\n",
    "f1_gb = f1_score(test_labels, pred_gb)\n",
    "acc_gb = accuracy_score(test_labels, pred_gb)\n",
    "# Print the scores.\n",
    "print(\"Accuracy-Score for Gradient Boosting Tree = %.3f\"%acc_gb)\n",
    "print(\"F1-Score for Gradient Boosting Tree = %.3f\"%f1_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOaJIOa0jQP_"
   },
   "source": [
    "# Applying Cross-Validation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-64rZXgXxxHM"
   },
   "source": [
    "## Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191584,
     "status": "ok",
     "timestamp": 1638704073865,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "dhfIUYIbi8a8",
    "outputId": "b6c32a30-e41c-41d1-8d51-4ee814440611"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(max_features='log2'), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 25, 50],\n",
       "                         'min_samples_leaf': [1, 4, 16],\n",
       "                         'min_samples_split': [64, 128, 256]},\n",
       "             refit='accuracy', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply gridSearch CV.\n",
    "params_dt = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "             \"min_samples_leaf\":[1, 4, 16],\n",
    "             \"max_depth\":[10, 25, 50],\n",
    "             \"min_samples_split\":[64, 128, 256]}# \"max_features\":[\"sqrt\", \"log2\"], ,\n",
    "dt_ = DecisionTreeClassifier(max_features = \"log2\")\n",
    "# Cv -splitter\n",
    "cv_splitter = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "dt_cv = GridSearchCV(dt_, params_dt, scoring = [\"accuracy\", \"f1\"], n_jobs = -1, cv = cv_splitter, refit=\"accuracy\")\n",
    "dt_cv.fit(train_val_data, train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd6TS_vUlm2m"
   },
   "outputs": [],
   "source": [
    "# Show the Results...\n",
    "dt_res = pd.DataFrame.from_dict(dt_cv.cv_results_)\n",
    "#dt_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1638704073868,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "LD9nnsAxlqqr",
    "outputId": "fa6526d4-1ae0-41ca-c326-72effef0ccc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV for Decision Tree:\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 128}\n",
      "Best Scores: 0.7198628061714372\n"
     ]
    }
   ],
   "source": [
    "# Show the Best params, and Best Score...\n",
    "print(f\"CV for Decision Tree:\\nBest Parameters: {dt_cv.best_params_}\\nBest Scores: {dt_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1638704073869,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "FcqUrt6V3iL8",
    "outputId": "4ada1628-e5a0-4d8d-8319-ff2429f2adfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6220847584857725 Accuracy Score 0.7198628061714372\n"
     ]
    }
   ],
   "source": [
    "# Print the best F1 and Accuracy score.\n",
    "print(\"F1 score: \", np.max(dt_res[\"mean_test_f1\"]), \"Accuracy Score\", np.max(dt_res[\"mean_test_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1638704074562,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "ICKW0uq-UwEV",
    "outputId": "ca71e04d-6f81-4fc5-b6ee-c0d87996c7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score for Decision Tree with Optimal Params = 0.725\n",
      "F1-Score for Decision Tree with Optimal Params = 0.634\n"
     ]
    }
   ],
   "source": [
    "# Now train the model with optimal hyper-parameters and obtain the result on test data-set.\n",
    "dt_optimal = DecisionTreeClassifier(max_features = \"log2\", \n",
    "                                    criterion = dt_cv.best_params_[\"criterion\"],\n",
    "                                    max_depth = dt_cv.best_params_[\"max_depth\"],\n",
    "                                    min_samples_split = dt_cv.best_params_[\"min_samples_split\"],\n",
    "                                    min_samples_leaf = dt_cv.best_params_[\"min_samples_leaf\"])\n",
    "# Train the DT.\n",
    "dt_optimal = dt_optimal.fit(train_val_data, train_val_labels)\n",
    "# Predict on vals.\n",
    "pred = dt_optimal.predict(test_data)\n",
    "# Accuracy and F1 score.\n",
    "f1_dt_optimal = f1_score(test_labels, pred)\n",
    "acc_dt_optimal = accuracy_score(test_labels, pred)\n",
    "# Print the scores.\n",
    "print(\"Accuracy-Score for Decision Tree with Optimal Params = %.3f\"%acc_dt_optimal)\n",
    "print(\"F1-Score for Decision Tree with Optimal Params = %.3f\"%f1_dt_optimal)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "WvL587ddltIM"
   },
   "source": [
    "# save the model to disk\n",
    "pickle.dump(dt_cv, open(ROOT + 'models/' + 'DT_CV_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSvVITnAx14D"
   },
   "source": [
    "## Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2047205,
     "status": "ok",
     "timestamp": 1638708504085,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "tZVCtR_Ax14E",
    "outputId": "5541ca18-9ee2-4ae1-db0e-bc58b9a72e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_features='log2',\n",
       "                                              min_samples_leaf=4, n_jobs=-1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [25],\n",
       "                         'min_samples_leaf': [1, 4],\n",
       "                         'min_samples_split': [32, 64, 128],\n",
       "                         'n_estimators': [200]},\n",
       "             refit='accuracy', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply gridSearch CV.\n",
    "params_rf = {\"n_estimators\":[200], \n",
    "             \"criterion\": [\"entropy\"], \n",
    "             \"max_depth\":[25],\n",
    "             \"min_samples_leaf\":[1, 4],\n",
    "             \"min_samples_split\":[32, 64, 128]}\n",
    "             # \"min_samples_split\":[2, 6, 16], \"min_samples_leaf\":[1, 4, 16],\n",
    "rf_ = RandomForestClassifier(n_jobs=-1, min_samples_leaf = 4, max_features = \"log2\")\n",
    "# Cv -splitter\n",
    "cv_splitter = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "rf_cv = GridSearchCV(rf_, params_rf, scoring = [\"accuracy\", \"f1\"], n_jobs = -1, cv = cv_splitter, refit=\"accuracy\")\n",
    "rf_cv.fit(train_val_data, train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1638708504086,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "x8S9_6lwx14F"
   },
   "outputs": [],
   "source": [
    "# Show the Results...\n",
    "rf_res = pd.DataFrame.from_dict(rf_cv.cv_results_)\n",
    "#rf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1638708504087,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "lXzuj0-ex14F",
    "outputId": "b504dcf8-8857-4b93-8db7-0c700d80e6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV for Random Forest:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 64, 'n_estimators': 200}\n",
      "Best Scores: 0.731257272651476\n"
     ]
    }
   ],
   "source": [
    "# Show the Best params, and Best Score...\n",
    "print(f\"CV for Random Forest:\\nBest Parameters: {rf_cv.best_params_}\\nBest Scores: {rf_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1638708504088,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "pS-UbShi37rf",
    "outputId": "ce5e7174-20a7-4e2f-fcab-7b1d445f8546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6422394175643088 Accuracy Score 0.731257272651476\n"
     ]
    }
   ],
   "source": [
    "# Print the best F1 and Accuracy score.\n",
    "print(\"F1 score: \", np.max(rf_res[\"mean_test_f1\"]), \"Accuracy Score\", np.max(rf_res[\"mean_test_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84709,
     "status": "ok",
     "timestamp": 1638708588782,
     "user": {
      "displayName": "Aditya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiER852yBfjgNprjlKJneRP7pZSPpehzbrF0FNS=s64",
      "userId": "03441126921159827598"
     },
     "user_tz": -330
    },
    "id": "fcS5SSFkWZHf",
    "outputId": "2bf81cff-b239-48ff-e47b-8b368435c50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-Score for Random Forest Classifier with Optimal Params = 0.737\n",
      "F1-Score for Random Forest Classifier with Optimal Params = 0.651\n"
     ]
    }
   ],
   "source": [
    "# Now train the model with optimal hyper-parameters and obtain the result on test data-set.\n",
    "rf_optimal = RandomForestClassifier(n_jobs=-1, \n",
    "                                    min_samples_leaf = rf_cv.best_params_[\"min_samples_leaf\"],\n",
    "                                    min_samples_split = rf_cv.best_params_[\"min_samples_split\"],\n",
    "                                    max_features = \"log2\", \n",
    "                                    criterion = rf_cv.best_params_[\"criterion\"],\n",
    "                                    max_depth = rf_cv.best_params_[\"max_depth\"],\n",
    "                                    n_estimators = rf_cv.best_params_[\"n_estimators\"])\n",
    "# Train the DT.\n",
    "rf_optimal = rf_optimal.fit(train_val_data, train_val_labels)\n",
    "# Predict on vals.\n",
    "pred = rf_optimal.predict(test_data)\n",
    "# Accuracy and F1 score.\n",
    "f1_rf_optimal = f1_score(test_labels, pred)\n",
    "acc_rf_optimal = accuracy_score(test_labels, pred)\n",
    "# Print the scores.\n",
    "print(\"Accuracy-Score for Random Forest Classifier with Optimal Params = %.3f\"%acc_rf_optimal)\n",
    "print(\"F1-Score for Random Forest Classifier with Optimal Params = %.3f\"%f1_rf_optimal)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "LajlRFGjx14F"
   },
   "source": [
    "# save the model to disk\n",
    "pickle.dump(rf_cv, open(ROOT + 'models/' + 'RF_CV_model.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdsXo/i1NUhnI8i2VvpLSg",
   "collapsed_sections": [],
   "name": "Trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
