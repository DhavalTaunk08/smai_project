{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-05T07:21:24.696231Z",
     "iopub.status.busy": "2021-12-05T07:21:24.695446Z",
     "iopub.status.idle": "2021-12-05T07:21:29.177093Z",
     "shell.execute_reply": "2021-12-05T07:21:29.176247Z",
     "shell.execute_reply.started": "2021-12-05T07:21:24.696089Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:21:29.179483Z",
     "iopub.status.busy": "2021-12-05T07:21:29.178997Z",
     "iopub.status.idle": "2021-12-05T07:21:32.486070Z",
     "shell.execute_reply": "2021-12-05T07:21:32.485330Z",
     "shell.execute_reply.started": "2021-12-05T07:21:29.179449Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/smai-project-data/train_data.csv').fillna('')\n",
    "val = pd.read_csv('../input/smai-project-data/val_data.csv').fillna('')\n",
    "test = pd.read_csv('../input/smai-project-data/test_data.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:21:32.489624Z",
     "iopub.status.busy": "2021-12-05T07:21:32.489415Z",
     "iopub.status.idle": "2021-12-05T07:21:32.511292Z",
     "shell.execute_reply": "2021-12-05T07:21:32.510674Z",
     "shell.execute_reply.started": "2021-12-05T07:21:32.489594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_preprocessed</th>\n",
       "      <th>question2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>how do i play pok mon go in korea ?</td>\n",
       "      <td>how do i play pok mon go in china ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>how do i improve logical programming skills ?</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>how close we are to see 3rd world war ?</td>\n",
       "      <td>how close is a world war iii ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0    8067   15738   15739                 How do I play Pokémon GO in Korea?   \n",
       "1  368101   12736  104117  What are some of the best side dishes for crab...   \n",
       "2   70497  121486  121487  Which is more advisable and better material fo...   \n",
       "3  226567  254474  258192       How do I improve logical programming skills?   \n",
       "4   73186   48103    3062             How close we are to see 3rd world war?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0                 How do I play Pokémon GO in China?             0   \n",
       "1  What are some good side dishes for buffalo chi...             0   \n",
       "2      What is the best server setup for buddypress?             0   \n",
       "3  How can I improve my logical skills for progra...             1   \n",
       "4                      How close is a World War III?             1   \n",
       "\n",
       "                              question1_preprocessed  \\\n",
       "0                how do i play pok mon go in korea ?   \n",
       "1  what are some of the best side dishes for crab...   \n",
       "2  which is more advisable and better material fo...   \n",
       "3      how do i improve logical programming skills ?   \n",
       "4            how close we are to see 3rd world war ?   \n",
       "\n",
       "                              question2_preprocessed  \n",
       "0                how do i play pok mon go in china ?  \n",
       "1  what are some good side dishes for buffalo chi...  \n",
       "2     what is the best server setup for buddypress ?  \n",
       "3  how can i improve my logical skills for progra...  \n",
       "4                     how close is a world war iii ?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:21:32.514130Z",
     "iopub.status.busy": "2021-12-05T07:21:32.513901Z",
     "iopub.status.idle": "2021-12-05T07:21:32.524800Z",
     "shell.execute_reply": "2021-12-05T07:21:32.524106Z",
     "shell.execute_reply.started": "2021-12-05T07:21:32.514094Z"
    }
   },
   "outputs": [],
   "source": [
    "def buildVocabulary(reviews):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False, split=' ')\n",
    "    tokenizer.fit_on_texts(reviews)\n",
    "    return tokenizer\n",
    "\n",
    "def getSequences(reviews, tokenizer, seq_maxlen):\n",
    "    reviews_seq = tokenizer.texts_to_sequences(reviews)\n",
    "    return np.array(tf.keras.preprocessing.sequence.pad_sequences(reviews_seq, maxlen=seq_maxlen))\n",
    "\n",
    "def loadGloveWordEmbeddings():\n",
    "    embedding_vectors = {}\n",
    "    with open('../input/glove840b300dtxt/glove.840B.300d.txt') as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_vectors[word] = coefs\n",
    "    return embedding_vectors\n",
    "\n",
    "def getEmbeddingWeightMatrix(embedding_vectors, word2idx):    \n",
    "    embedding_matrix = np.zeros((len(word2idx)+1, 300))\n",
    "    for word, i in tqdm(word2idx.items()):\n",
    "        embedding_vector = embedding_vectors.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:21:32.526477Z",
     "iopub.status.busy": "2021-12-05T07:21:32.526215Z",
     "iopub.status.idle": "2021-12-05T07:22:04.067116Z",
     "shell.execute_reply": "2021-12-05T07:22:04.066259Z",
     "shell.execute_reply.started": "2021-12-05T07:21:32.526443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119558\n"
     ]
    }
   ],
   "source": [
    "tokenizer = buildVocabulary(train['question1'].tolist()+train['question2'].tolist()+val['question1'].tolist()+val['question2'].tolist()+test['question1'].tolist()+test['question2'].tolist())\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "x_train1 = getSequences(train['question1'], tokenizer, 128)\n",
    "x_train2 = getSequences(train['question2'], tokenizer, 128)\n",
    "y_train = tf.keras.utils.to_categorical(train['is_duplicate'])\n",
    "\n",
    "x_val1 = getSequences(val['question1'], tokenizer, 128)\n",
    "x_val2 = getSequences(val['question2'], tokenizer, 128)\n",
    "y_val = tf.keras.utils.to_categorical(val['is_duplicate'])\n",
    "\n",
    "x_test1 = getSequences(test['question1'], tokenizer, 128)\n",
    "x_test2 = getSequences(test['question2'], tokenizer, 128)\n",
    "y_test = tf.keras.utils.to_categorical(test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:22:04.068714Z",
     "iopub.status.busy": "2021-12-05T07:22:04.068455Z",
     "iopub.status.idle": "2021-12-05T07:26:17.684935Z",
     "shell.execute_reply": "2021-12-05T07:26:17.684071Z",
     "shell.execute_reply.started": "2021-12-05T07:22:04.068679Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [04:13, 8673.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119557/119557 [00:00<00:00, 289620.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119558, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = loadGloveWordEmbeddings()\n",
    "print(len(embedding_vectors))\n",
    "\n",
    "embedding_weight_matrix = getEmbeddingWeightMatrix(embedding_vectors, tokenizer.word_index)\n",
    "print(embedding_weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:28:18.980466Z",
     "iopub.status.busy": "2021-12-05T07:28:18.979883Z",
     "iopub.status.idle": "2021-12-05T07:28:19.835475Z",
     "shell.execute_reply": "2021-12-05T07:28:19.834704Z",
     "shell.execute_reply.started": "2021-12-05T07:28:18.980425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 07:28:19.052944: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 143469600 exceeds 10% of free system memory.\n",
      "2021-12-05 07:28:19.259332: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 143469600 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "inp1 = tf.keras.Input(shape=(x_train1.shape[1],))\n",
    "inp2 = tf.keras.Input(shape=(x_train2.shape[1],))\n",
    "\n",
    "inner1= tf.keras.layers.Embedding(input_dim=119558, output_dim=300, input_length=128, \n",
    "                                  weights=[embedding_weight_matrix], trainable=False)(inp1)\n",
    "inner2= tf.keras.layers.Embedding(input_dim=119558, output_dim=300, input_length=128,\n",
    "                                  weights=[embedding_weight_matrix], trainable=False)(inp2)\n",
    "\n",
    "inner = tf.keras.layers.concatenate([inner1+inner2, inner1-inner2, tf.math.multiply(inner1, inner2)], axis=-1)\n",
    "\n",
    "out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, kernel_regularizer='l2', dropout=0.1, return_sequences=True))(inner)\n",
    "\n",
    "out = tf.keras.backend.mean(out, axis=1, keepdims=False)\n",
    "\n",
    "output = tf.keras.layers.Dense(2, kernel_regularizer='l2', activation='softmax')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs = [inp1, inp2], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:28:22.230481Z",
     "iopub.status.busy": "2021-12-05T07:28:22.229633Z",
     "iopub.status.idle": "2021-12-05T07:28:22.254231Z",
     "shell.execute_reply": "2021-12-05T07:28:22.252329Z",
     "shell.execute_reply.started": "2021-12-05T07:28:22.230431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 128, 300)     35867400    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 128, 300)     35867400    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 128, 300)     0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 128, 300)     0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 128, 300)     0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 900)     0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.math.subtract_1[0][0]         \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 300)     1261200     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 300)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            602         tf.math.reduce_mean_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 72,996,602\n",
      "Trainable params: 1,261,802\n",
      "Non-trainable params: 71,734,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T07:54:34.407682Z",
     "iopub.status.busy": "2021-12-05T07:54:34.406978Z",
     "iopub.status.idle": "2021-12-05T08:02:56.589419Z",
     "shell.execute_reply": "2021-12-05T08:02:56.588628Z",
     "shell.execute_reply.started": "2021-12-05T07:54:34.407647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8844/8844 [==============================] - 249s 28ms/step - loss: 0.5754 - accuracy: 0.7337 - val_loss: 0.5890 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58903, saving model to weights.best.hdf5\n",
      "Epoch 2/2\n",
      "8844/8844 [==============================] - 249s 28ms/step - loss: 0.5752 - accuracy: 0.7361 - val_loss: 0.5766 - val_accuracy: 0.7340\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58903 to 0.57661, saving model to weights.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath  = 'weights.best.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                verbose = 1, \n",
    "                                                                monitor = 'val_loss',\n",
    "                                                                save_best_only = True)\n",
    "\n",
    "history = model.fit((x_train1, x_train2), y_train,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = ((x_val1, x_val2), y_val),\n",
    "                    validation_batch_size = 16,\n",
    "                    epochs=5,\n",
    "                    callbacks=[model_checkpoint_callback], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:02:57.030112Z",
     "iopub.status.busy": "2021-12-05T08:02:57.029591Z",
     "iopub.status.idle": "2021-12-05T08:04:06.879698Z",
     "shell.execute_reply": "2021-12-05T08:04:06.878884Z",
     "shell.execute_reply.started": "2021-12-05T08:02:57.030075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10108/10108 [==============================] - 70s 7ms/step - loss: 0.5730 - accuracy: 0.7340\n",
      "loss on test data is 0.5730125308036804\n",
      "accuracy on test data is 0.7340275645256042\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate((x_test1, x_test2), y_test, batch_size=4, verbose=1)\n",
    "\n",
    "print('loss on test data is', loss)\n",
    "print('accuracy on test data is', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:04:06.881174Z",
     "iopub.status.busy": "2021-12-05T08:04:06.880894Z",
     "iopub.status.idle": "2021-12-05T08:04:17.186473Z",
     "shell.execute_reply": "2021-12-05T08:04:17.185721Z",
     "shell.execute_reply.started": "2021-12-05T08:04:06.881138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on test dataset is 0.6310516383599245\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict((x_test1, x_test2))\n",
    "\n",
    "print('f1_score on test dataset is', f1_score(np.argmax(pred, axis=1), np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
