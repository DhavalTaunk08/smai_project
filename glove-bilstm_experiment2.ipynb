{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-05T08:27:55.991770Z",
     "iopub.status.busy": "2021-12-05T08:27:55.991383Z",
     "iopub.status.idle": "2021-12-05T08:28:00.572205Z",
     "shell.execute_reply": "2021-12-05T08:28:00.571459Z",
     "shell.execute_reply.started": "2021-12-05T08:27:55.991676Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:28:00.575744Z",
     "iopub.status.busy": "2021-12-05T08:28:00.575547Z",
     "iopub.status.idle": "2021-12-05T08:28:03.698196Z",
     "shell.execute_reply": "2021-12-05T08:28:03.697341Z",
     "shell.execute_reply.started": "2021-12-05T08:28:00.575719Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/smai-project-data/train_data.csv').fillna('')\n",
    "val = pd.read_csv('../input/smai-project-data/val_data.csv').fillna('')\n",
    "test = pd.read_csv('../input/smai-project-data/test_data.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:28:03.701370Z",
     "iopub.status.busy": "2021-12-05T08:28:03.699765Z",
     "iopub.status.idle": "2021-12-05T08:28:03.725788Z",
     "shell.execute_reply": "2021-12-05T08:28:03.725005Z",
     "shell.execute_reply.started": "2021-12-05T08:28:03.701323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_preprocessed</th>\n",
       "      <th>question2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "      <td>how do i play pok mon go in korea ?</td>\n",
       "      <td>how do i play pok mon go in china ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>how do i improve logical programming skills ?</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "      <td>how close we are to see 3rd world war ?</td>\n",
       "      <td>how close is a world war iii ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0    8067   15738   15739                 How do I play Pokémon GO in Korea?   \n",
       "1  368101   12736  104117  What are some of the best side dishes for crab...   \n",
       "2   70497  121486  121487  Which is more advisable and better material fo...   \n",
       "3  226567  254474  258192       How do I improve logical programming skills?   \n",
       "4   73186   48103    3062             How close we are to see 3rd world war?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0                 How do I play Pokémon GO in China?             0   \n",
       "1  What are some good side dishes for buffalo chi...             0   \n",
       "2      What is the best server setup for buddypress?             0   \n",
       "3  How can I improve my logical skills for progra...             1   \n",
       "4                      How close is a World War III?             1   \n",
       "\n",
       "                              question1_preprocessed  \\\n",
       "0                how do i play pok mon go in korea ?   \n",
       "1  what are some of the best side dishes for crab...   \n",
       "2  which is more advisable and better material fo...   \n",
       "3      how do i improve logical programming skills ?   \n",
       "4            how close we are to see 3rd world war ?   \n",
       "\n",
       "                              question2_preprocessed  \n",
       "0                how do i play pok mon go in china ?  \n",
       "1  what are some good side dishes for buffalo chi...  \n",
       "2     what is the best server setup for buddypress ?  \n",
       "3  how can i improve my logical skills for progra...  \n",
       "4                     how close is a world war iii ?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:28:03.728265Z",
     "iopub.status.busy": "2021-12-05T08:28:03.727992Z",
     "iopub.status.idle": "2021-12-05T08:28:03.737968Z",
     "shell.execute_reply": "2021-12-05T08:28:03.736992Z",
     "shell.execute_reply.started": "2021-12-05T08:28:03.728229Z"
    }
   },
   "outputs": [],
   "source": [
    "def buildVocabulary(reviews):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False, split=' ')\n",
    "    tokenizer.fit_on_texts(reviews)\n",
    "    return tokenizer\n",
    "\n",
    "def getSequences(reviews, tokenizer, seq_maxlen):\n",
    "    reviews_seq = tokenizer.texts_to_sequences(reviews)\n",
    "    return np.array(tf.keras.preprocessing.sequence.pad_sequences(reviews_seq, maxlen=seq_maxlen))\n",
    "\n",
    "def loadGloveWordEmbeddings():\n",
    "    embedding_vectors = {}\n",
    "    with open('../input/glove840b300dtxt/glove.840B.300d.txt') as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_vectors[word] = coefs\n",
    "    return embedding_vectors\n",
    "\n",
    "def getEmbeddingWeightMatrix(embedding_vectors, word2idx):    \n",
    "    embedding_matrix = np.zeros((len(word2idx)+1, 300))\n",
    "    for word, i in tqdm(word2idx.items()):\n",
    "        embedding_vector = embedding_vectors.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:28:03.740285Z",
     "iopub.status.busy": "2021-12-05T08:28:03.739650Z",
     "iopub.status.idle": "2021-12-05T08:28:35.589006Z",
     "shell.execute_reply": "2021-12-05T08:28:35.588270Z",
     "shell.execute_reply.started": "2021-12-05T08:28:03.740250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119558\n"
     ]
    }
   ],
   "source": [
    "tokenizer = buildVocabulary(train['question1'].tolist()+train['question2'].tolist()+val['question1'].tolist()+val['question2'].tolist()+test['question1'].tolist()+test['question2'].tolist())\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "x_train1 = getSequences(train['question1'], tokenizer, 128)\n",
    "x_train2 = getSequences(train['question2'], tokenizer, 128)\n",
    "y_train = tf.keras.utils.to_categorical(train['is_duplicate'])\n",
    "\n",
    "x_val1 = getSequences(val['question1'], tokenizer, 128)\n",
    "x_val2 = getSequences(val['question2'], tokenizer, 128)\n",
    "y_val = tf.keras.utils.to_categorical(val['is_duplicate'])\n",
    "\n",
    "x_test1 = getSequences(test['question1'], tokenizer, 128)\n",
    "x_test2 = getSequences(test['question2'], tokenizer, 128)\n",
    "y_test = tf.keras.utils.to_categorical(test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:28:35.590734Z",
     "iopub.status.busy": "2021-12-05T08:28:35.590499Z",
     "iopub.status.idle": "2021-12-05T08:32:50.715266Z",
     "shell.execute_reply": "2021-12-05T08:32:50.714504Z",
     "shell.execute_reply.started": "2021-12-05T08:28:35.590699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [04:14, 8621.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119557/119557 [00:00<00:00, 296253.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119558, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = loadGloveWordEmbeddings()\n",
    "print(len(embedding_vectors))\n",
    "\n",
    "embedding_weight_matrix = getEmbeddingWeightMatrix(embedding_vectors, tokenizer.word_index)\n",
    "print(embedding_weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:32:50.717025Z",
     "iopub.status.busy": "2021-12-05T08:32:50.716763Z",
     "iopub.status.idle": "2021-12-05T08:32:54.266862Z",
     "shell.execute_reply": "2021-12-05T08:32:54.266168Z",
     "shell.execute_reply.started": "2021-12-05T08:32:50.716989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 08:32:50.811328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:50.924265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:50.924979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:50.926274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-05 08:32:50.927066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:50.927770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:50.928410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:52.819781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:52.820602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:52.821254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-05 08:32:52.821837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2021-12-05 08:32:53.377677: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 143469600 exceeds 10% of free system memory.\n",
      "2021-12-05 08:32:53.611921: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 143469600 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "inp1 = tf.keras.Input(shape=(x_train1.shape[1],))\n",
    "inp2 = tf.keras.Input(shape=(x_train2.shape[1],))\n",
    "\n",
    "inner1= tf.keras.layers.Embedding(input_dim=119558, output_dim=300, input_length=128, \n",
    "                                  weights=[embedding_weight_matrix], trainable=False)(inp1)\n",
    "inner2= tf.keras.layers.Embedding(input_dim=119558, output_dim=300, input_length=128,\n",
    "                                  weights=[embedding_weight_matrix], trainable=False)(inp2)\n",
    "\n",
    "inner = tf.keras.layers.concatenate([inner1+inner2, inner1-inner2, tf.math.multiply(inner1, inner2)], axis=-1)\n",
    "\n",
    "out = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, kernel_regularizer='l2', return_sequences=True))(inner)\n",
    "\n",
    "out = tf.keras.backend.mean(out, axis=1, keepdims=False)\n",
    "\n",
    "output = tf.keras.layers.Dense(2, kernel_regularizer='l2', activation='softmax')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs = [inp1, inp2], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:32:54.268296Z",
     "iopub.status.busy": "2021-12-05T08:32:54.268035Z",
     "iopub.status.idle": "2021-12-05T08:32:54.288773Z",
     "shell.execute_reply": "2021-12-05T08:32:54.288146Z",
     "shell.execute_reply.started": "2021-12-05T08:32:54.268263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 128, 300)     35867400    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 300)     35867400    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 128, 300)     0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 128, 300)     0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 128, 300)     0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 900)     0           tf.__operators__.add[0][0]       \n",
      "                                                                 tf.math.subtract[0][0]           \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 300)     1261200     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 300)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            602         tf.math.reduce_mean[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 72,996,602\n",
      "Trainable params: 1,261,802\n",
      "Non-trainable params: 71,734,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:32:54.290164Z",
     "iopub.status.busy": "2021-12-05T08:32:54.289923Z",
     "iopub.status.idle": "2021-12-05T08:54:19.362354Z",
     "shell.execute_reply": "2021-12-05T08:54:19.361515Z",
     "shell.execute_reply.started": "2021-12-05T08:32:54.290131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 08:32:54.295725: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 144897536 exceeds 10% of free system memory.\n",
      "2021-12-05 08:32:54.402477: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 144897536 exceeds 10% of free system memory.\n",
      "2021-12-05 08:32:54.568071: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 08:32:58.225519: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8844/8844 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.7057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 08:36:24.846568: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 41399296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8844/8844 [==============================] - 250s 28ms/step - loss: 0.6319 - accuracy: 0.7057 - val_loss: 0.5694 - val_accuracy: 0.7317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56941, saving model to weights.best.hdf5\n",
      "Epoch 2/5\n",
      "8844/8844 [==============================] - 245s 28ms/step - loss: 0.5812 - accuracy: 0.7274 - val_loss: 0.5639 - val_accuracy: 0.7362\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56941 to 0.56394, saving model to weights.best.hdf5\n",
      "Epoch 3/5\n",
      "8844/8844 [==============================] - 243s 28ms/step - loss: 0.5915 - accuracy: 0.7223 - val_loss: 0.6492 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56394\n",
      "Epoch 4/5\n",
      "8844/8844 [==============================] - 244s 28ms/step - loss: 0.5840 - accuracy: 0.7287 - val_loss: 0.5697 - val_accuracy: 0.7288\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56394\n",
      "Epoch 5/5\n",
      "8844/8844 [==============================] - 243s 28ms/step - loss: 0.5734 - accuracy: 0.7334 - val_loss: 0.5623 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56394 to 0.56234, saving model to weights.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath  = 'weights.best.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                verbose = 1, \n",
    "                                                                monitor = 'val_loss',\n",
    "                                                                save_best_only = True)\n",
    "\n",
    "history = model.fit((x_train1, x_train2), y_train,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = ((x_val1, x_val2), y_val),\n",
    "                    validation_batch_size = 16,\n",
    "                    epochs=5,\n",
    "                    callbacks=[model_checkpoint_callback], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:54:19.834213Z",
     "iopub.status.busy": "2021-12-05T08:54:19.833805Z",
     "iopub.status.idle": "2021-12-05T08:55:29.256507Z",
     "shell.execute_reply": "2021-12-05T08:55:29.255776Z",
     "shell.execute_reply.started": "2021-12-05T08:54:19.834175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10108/10108 [==============================] - 69s 7ms/step - loss: 0.5629 - accuracy: 0.7411\n",
      "loss on test data is 0.5628555417060852\n",
      "accuracy on test data is 0.7410769462585449\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate((x_test1, x_test2), y_test, batch_size=4, verbose=1)\n",
    "\n",
    "print('loss on test data is', loss)\n",
    "print('accuracy on test data is', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T08:55:29.258466Z",
     "iopub.status.busy": "2021-12-05T08:55:29.258123Z",
     "iopub.status.idle": "2021-12-05T08:55:40.114361Z",
     "shell.execute_reply": "2021-12-05T08:55:40.113551Z",
     "shell.execute_reply.started": "2021-12-05T08:55:29.258423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on test dataset is 0.6306802145074795\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict((x_test1, x_test2))\n",
    "\n",
    "print('f1_score on test dataset is', f1_score(np.argmax(pred, axis=1), np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
